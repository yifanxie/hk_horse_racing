{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a22bb55-288f-4d08-9556-e7d437fdcd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from typing import Optional\n",
    "import glob\n",
    "from scipy import stats\n",
    "# Add the parent directory of this notebook to sys.path\n",
    "notebook_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from project_tools import project_utils, project_class\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "# import ds_utils\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, ndcg_score\n",
    "from scipy.stats import kendalltau, spearmanr\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from importlib import reload\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.0f' % x)\n",
    "\n",
    "# Or for more precise control\n",
    "pd.set_option('display.float_format', '{:.5f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b1d0f2-e53f-4a5b-9c2c-c5c3da0c39fa",
   "metadata": {},
   "source": [
    "# load_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e61b7e2a-1ade-47d6-b197-3bf03948b2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_horse_race_df = pd.read_parquet('../feature_data/train_horse_race_df.parquet')\n",
    "# val_horse_race_df = pd.read_parquet('../feature_data/val_horse_race_df.parquet')                           \n",
    "horse_race_df = pd.read_parquet('../feature_data/horse_race_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf15cd81-7db9-49be-a9dc-1b902f46dcfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic_cat_ordinal_features.parquet\n",
      "horse_class_feats.parquet\n",
      "horse_feats.parquet\n",
      "horse_running_position_features.parquet\n",
      "horse_track_running_position_features.parquet\n",
      "race_course_features.parquet\n",
      "trace_condition.parquet\n",
      "train_horse_positions_df.parquet\n",
      "train_horse_race_df.parquet\n",
      "train_jockey_positions_df.parquet\n",
      "train_trainer_positions_df.parquet\n",
      "val_horse_race_df.parquet\n"
     ]
    }
   ],
   "source": [
    "# load generated featureset\n",
    "!ls ../feature_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ef06c80-3a5e-4860-b7bc-6db3b9aeb44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load features\n",
    "basic_cat_ordinal_df = pd.read_parquet('../feature_data/basic_cat_ordinal_features.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34355c43-3738-4c71-952d-77bdeb12852f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29520, 44)\n",
      "(29520, 6)\n"
     ]
    }
   ],
   "source": [
    "print(horse_race_df.shape)\n",
    "print(basic_cat_ordinal_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b8ddad4b-b0eb-4024-994d-18bce407db12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load baseline evaluation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9abbf3e2-1274-4023-9535-174236586a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_mean_results = pd.read_parquet('../evaluation_results/valdf_random_winodd_baseline_mean_results.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b7414f9f-f179-4666-a177-2078931cdebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random_probs</th>\n",
       "      <th>winning_odd_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <td>25.28416</td>\n",
       "      <td>23.58429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <td>4.04875</td>\n",
       "      <td>3.87116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spearman's Rank Correlation</th>\n",
       "      <td>0.02009</td>\n",
       "      <td>0.07598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDCG</th>\n",
       "      <td>0.83467</td>\n",
       "      <td>0.74502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winner Match</th>\n",
       "      <td>0.06654</td>\n",
       "      <td>0.11155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top 3 Set Match</th>\n",
       "      <td>0.00391</td>\n",
       "      <td>0.00196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top 3 Exact Match</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             random_probs  winning_odd_preds\n",
       "Mean Squared Error               25.28416           23.58429\n",
       "Mean Absolute Error               4.04875            3.87116\n",
       "Spearman's Rank Correlation       0.02009            0.07598\n",
       "NDCG                              0.83467            0.74502\n",
       "Winner Match                      0.06654            0.11155\n",
       "Top 3 Set Match                   0.00391            0.00196\n",
       "Top 3 Exact Match                 0.00000            0.00000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_mean_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf478806-2947-4f98-a0c3-a1d950952367",
   "metadata": {},
   "source": [
    "# evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "00bbe6ee-8f8b-459b-8ffd-cda91d067b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_horse_race_positions(y_true, y_pred_proba, dnf_value=99):\n",
    "    \"\"\"\n",
    "    Evaluate predictions for a single race's finishing positions.\n",
    "    \n",
    "    Args:\n",
    "        y_true: 1D array of true finishing positions\n",
    "        y_pred_proba: 1D array of predicted probabilities\n",
    "        dnf_value: Value used to indicate Did Not Finish\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    # Handle NaN and DNF values in ground truth\n",
    "    y_true_processed = y_true.copy()\n",
    "    invalid_mask = np.logical_or(\n",
    "        np.isnan(y_true),\n",
    "        y_true == dnf_value\n",
    "    )\n",
    "    \n",
    "    # Get max valid rank (excluding DNF values)\n",
    "    valid_ranks = y_true[~invalid_mask]\n",
    "    if len(valid_ranks) > 0:\n",
    "        max_rank = np.max(valid_ranks)\n",
    "        # Replace invalid values with max_rank + 1\n",
    "        y_true_processed[invalid_mask] = max_rank + 1\n",
    "        \n",
    "    # Winner match\n",
    "    y_true_ranksort = np.argsort(y_true_processed)\n",
    "    y_pred_ranksort = np.argsort(y_pred_proba, axis=0)[::-1]\n",
    "    \n",
    "    winner_match = y_true_ranksort[0] == y_pred_ranksort[0]\n",
    "    \n",
    "    # Top 3 Set Match - considers [1,3,2] and [2,3,1] as matching\n",
    "    top3_set_match = set(y_true_ranksort[:3]) == set(y_pred_ranksort[:3])\n",
    "    \n",
    "    # Top 3 Exact Match - only considers exact matches like [1,3,2] and [1,3,2]\n",
    "    top3_exact_match = np.array_equal(y_true_ranksort[:3], y_pred_ranksort[:3])\n",
    "    \n",
    "    return {\n",
    "        'Winner Match': float(winner_match),\n",
    "        'Top 3 Set Match': float(top3_set_match), \n",
    "        'Top 3 Exact Match': float(top3_exact_match)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a4d7d4bf-9c83-445e-9525-f3d37d31bd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prediction_sets(eval_dict):\n",
    "    \"\"\"\n",
    "    Evaluate different prediction sets against ground truth for each race and calculate mean metrics\n",
    "    \n",
    "    Args:\n",
    "        eval_dict: Dictionary containing race data with ground truth and different prediction sets\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (eval_result, mean_results_df)\n",
    "            - eval_result: Dictionary with detailed evaluation metrics for each race\n",
    "            - mean_results_df: DataFrame comparing mean metrics across prediction types\n",
    "    \"\"\"\n",
    "    # Initialize results dictionary with race_ids as first level keys\n",
    "    eval_result = {race_id: {} for race_id in eval_dict}\n",
    "\n",
    "    # Get prediction types from first race data\n",
    "    first_race_id = next(iter(eval_dict))\n",
    "    pred_types = [key for key in eval_dict[first_race_id].keys() if key != 'ground_truth']\n",
    "\n",
    "    # Initialize dictionaries to store mean results\n",
    "    mean_results = {pred_type: {} for pred_type in pred_types}\n",
    "\n",
    "    # Loop through each race\n",
    "    for race_id in eval_dict:\n",
    "        race_data = eval_dict[race_id]\n",
    "        ground_truth = race_data['ground_truth']\n",
    "        \n",
    "        # Evaluate each prediction type\n",
    "        for pred_type in pred_types:\n",
    "            pred_probs = race_data[pred_type]\n",
    "            \n",
    "            # Evaluate predictions for this race\n",
    "            race_eval = evaluate_horse_race_positions(\n",
    "                ground_truth,\n",
    "                pred_probs\n",
    "            )\n",
    "            \n",
    "            # Store results for this race under race_id first, then pred_type\n",
    "            eval_result[race_id][pred_type] = race_eval\n",
    "\n",
    "    # Calculate mean results for each prediction type\n",
    "    for pred_type in pred_types:\n",
    "        # Initialize dict to store means for each metric\n",
    "        metric_means = {}\n",
    "        \n",
    "        # Get metrics from first race to know what metrics exist\n",
    "        first_race = next(iter(eval_result.values()))\n",
    "        metrics = first_race[pred_type].keys()\n",
    "        \n",
    "        # For each metric, calculate mean across all races\n",
    "        for metric in metrics:\n",
    "            total = 0\n",
    "            num_races = 0\n",
    "            for race_id in eval_result:\n",
    "                total += eval_result[race_id][pred_type][metric]\n",
    "                num_races += 1\n",
    "            metric_means[metric] = total / num_races\n",
    "            \n",
    "        mean_results[pred_type] = metric_means\n",
    "    \n",
    "    # Convert mean results to DataFrame for easy comparison\n",
    "    mean_results_df = pd.DataFrame(mean_results)\n",
    "    \n",
    "    return eval_result, mean_results_df\n",
    "\n",
    "# # Run evaluation\n",
    "# eval_result, mean_results_df = evaluate_prediction_sets(eval_dict)\n",
    "\n",
    "# # Display mean results comparison\n",
    "# print(\"\\nMean Evaluation Metrics Comparison:\")\n",
    "# print(mean_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddd0bb2-b1e6-4a2d-82ca-b8163fc88ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37e321e6-2bc9-46a3-bbd6-1f3b46a56405",
   "metadata": {},
   "source": [
    "# getting basic feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f0450a7-9172-40db-a0d1-7897c40a7fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "850d687f-e897-4c76-9f6d-85739c56affb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lightgbm_model(train_df, val_df, label_col, cat_features=None, params=None):\n",
    "    \"\"\"\n",
    "    Train a LightGBM model for binary classification using LGBMClassifier\n",
    "    \n",
    "    Args:\n",
    "        train_df: Training dataframe containing features and label\n",
    "        val_df: Validation dataframe containing features and label  \n",
    "        label_col: Name of label column (should contain binary values 0/1)\n",
    "        cat_features: List of categorical feature names\n",
    "        params: Dict of LightGBM parameters\n",
    "        \n",
    "    Returns:\n",
    "        Trained model and validation predictions\n",
    "    \"\"\"\n",
    "    # Default parameters if none provided\n",
    "    if params is None:\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_logloss',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'n_estimators':150,\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,  # Column sampling\n",
    "            'bagging_fraction': 0.8,  # Row sampling \n",
    "            'bagging_freq': 5,\n",
    "            'verbose': -1,\n",
    "            'max_depth': -1,\n",
    "            'min_child_samples': 20,\n",
    "            'reg_alpha': 0.0,\n",
    "            'reg_lambda': 0.0,\n",
    "            'is_unbalance': True  # Handle unbalanced datasets\n",
    "        }\n",
    "\n",
    "    # Separate features and labels\n",
    "    features = [col for col in train_df.columns if col != label_col]\n",
    "    X_train = train_df[features]\n",
    "    y_train = train_df[label_col]\n",
    "    X_val = val_df[features]\n",
    "    y_val = val_df[label_col]\n",
    "\n",
    "    # Initialize and train model\n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    \n",
    "    # Fit model with early stopping\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        categorical_feature=cat_features if cat_features else 'auto'\n",
    "    )\n",
    "    \n",
    "    # Make validation predictions\n",
    "    val_preds = model.predict_proba(X_val)[:, 1]  # Get probability of positive class\n",
    "    val_logloss = log_loss(y_val, val_preds)\n",
    "    # val_acc = accuracy_score(y_val, val_preds > 0.5)  # Convert probs to binary predictions\n",
    "    print(f'Validation LogLoss: {val_logloss:.4f}')\n",
    "    # print(f'Validation Accuracy: {val_acc:.4f}')\n",
    "    \n",
    "    return model, val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4b0efdb-02ef-41d1-84f4-cb86a1a103c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29520, 44)\n",
      "(29520, 6)\n"
     ]
    }
   ],
   "source": [
    "print(horse_race_df.shape)\n",
    "print(basic_cat_ordinal_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37c9fa87-dff5-4351-bf54-95732b0509fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23232 6288\n"
     ]
    }
   ],
   "source": [
    "train_years = ['2014','2015','2016']\n",
    "val_years = ['2017']\n",
    "train_idx = horse_race_df[horse_race_df['year'].isin(train_years)].index\n",
    "val_idx = horse_race_df[horse_race_df['year'].isin(val_years)].index\n",
    "print(len(train_idx), len(val_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4c53edc1-4a3a-4766-adb7-1ea800015007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23232, 15) (6288, 15)\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'n_estimators':300,\n",
    "    'num_leaves': 32,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.8,  # Column sampling\n",
    "    'bagging_fraction': 0.8,  # Row sampling \n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1,\n",
    "    'max_depth': -1,\n",
    "    'min_child_samples': 20,\n",
    "    'is_unbalance': True  # Handle unbalanced datasets\n",
    "}\n",
    "\n",
    "\n",
    "# first past featureset:\n",
    "target = 'is_winner'\n",
    "basic_num_features = ['horse_number', 'clean_actual_weight', 'clean_declared_horse_weight',\n",
    "                  'clean_win_odds', 'race_distance', 'clean_position_mavg_3', 'clean_position_mavg_5',\n",
    "                     'clean_position_mavg_7']\n",
    "\n",
    "\n",
    "basic_cat_features = basic_cat_ordinal_df.columns.tolist()\n",
    "\n",
    "df = pd.concat([horse_race_df[basic_num_features], basic_cat_ordinal_df], axis=1)\n",
    "df[target] = horse_race_df[target]\n",
    "\n",
    "train_df = df.loc[train_idx]\n",
    "val_df = df.loc[val_idx]\n",
    "\n",
    "print(train_df.shape, val_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc362a94-8cb8-4da0-a217-739b29b77e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b5265f8-dfb0-45ab-82e8-5cdc5e6ea7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['horse_number', 'clean_actual_weight', 'clean_declared_horse_weight',\n",
       "       'clean_win_odds', 'race_distance', 'clean_position_mavg_3',\n",
       "       'clean_position_mavg_5', 'clean_position_mavg_7', 'jockey', 'trainer',\n",
       "       'race_course', 'race_course_track', 'race_class', 'track_condition',\n",
       "       'is_winner'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb43b15-465f-45f1-83f9-520af19f5076",
   "metadata": {},
   "source": [
    "# lightgbm with basic featureset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f0900226-5fad-4673-b1ad-57e3302a302b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation LogLoss: 0.3241\n"
     ]
    }
   ],
   "source": [
    "model, val_preds = train_lightgbm_model(train_df, val_df, target,\n",
    "                                        cat_features=basic_cat_features, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "697fdfbe-b405-4269-acfd-26a23fd1f5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation \n",
    "val_horse_race_df = horse_race_df.loc[val_idx].reset_index(drop=True)\n",
    "val_horse_race_df['lgbm_v0_preds'] = val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6dd36dfb-0e01-4888-aaa2-81277a00a42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_id</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>clean_position</th>\n",
       "      <th>is_winner</th>\n",
       "      <th>lgbm_v0_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>2016-362</td>\n",
       "      <td>S432</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.19884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>2016-362</td>\n",
       "      <td>P064</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>2016-362</td>\n",
       "      <td>S367</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.81773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>2016-362</td>\n",
       "      <td>V144</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.29130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>2016-362</td>\n",
       "      <td>V129</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.04883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>2016-362</td>\n",
       "      <td>N265</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>2016-362</td>\n",
       "      <td>S087</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.33429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>2016-362</td>\n",
       "      <td>T356</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>2016-362</td>\n",
       "      <td>P105</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>2016-362</td>\n",
       "      <td>S413</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>2016-362</td>\n",
       "      <td>M273</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      race_id horse_id  clean_position  is_winner  lgbm_v0_preds\n",
       "824  2016-362     S432               1          1        0.19884\n",
       "825  2016-362     P064               2          0        0.06689\n",
       "826  2016-362     S367               3          0        0.81773\n",
       "827  2016-362     V144               4          0        0.29130\n",
       "828  2016-362     V129               5          0        0.04883\n",
       "829  2016-362     N265               6          0        0.03290\n",
       "830  2016-362     S087               7          0        0.33429\n",
       "831  2016-362     T356               8          0        0.02665\n",
       "832  2016-362     P105               9          0        0.08548\n",
       "833  2016-362     S413              10          0        0.00160\n",
       "834  2016-362     M273              11          0        0.00957"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_race_id = val_horse_race_df['race_id'].sample(1).values[0]\n",
    "use_cols = ['race_id', 'horse_id', 'clean_position', 'is_winner', 'lgbm_v0_preds']\n",
    "val_horse_race_df[val_horse_race_df['race_id']==check_race_id][use_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "439cef05-8b95-4c35-9983-0e2e71122d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dict = {}\n",
    "ground_truth = {}\n",
    "lgbm_v0_preds = [] \n",
    "\n",
    "for race in val_horse_race_df['race_id'].unique():\n",
    "    race_df = val_horse_race_df[val_horse_race_df['race_id']==race]\n",
    "    n_horse = race_df.shape[0]    \n",
    "    eval_dict[race] = {}\n",
    "    eval_dict[race]['ground_truth'] = race_df['clean_position'].values\n",
    "    eval_dict[race]['lgbm_v0_preds'] = -1* race_df['clean_win_odds'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8f7348e5-4399-4f50-954e-00f89f77283e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result, lgbmv0_results_df = evaluate_prediction_sets(eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a90da785-6b3e-4c3a-9f3c-07407a14bb98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgbm_v0_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Winner Match</th>\n",
       "      <td>0.28963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top 3 Set Match</th>\n",
       "      <td>0.05479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top 3 Exact Match</th>\n",
       "      <td>0.00978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   lgbm_v0_preds\n",
       "Winner Match             0.28963\n",
       "Top 3 Set Match          0.05479\n",
       "Top 3 Exact Match        0.00978"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbmv0_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "48d3752d-dded-4d5d-a8cb-41bd3d5c7d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random_probs</th>\n",
       "      <th>winning_odd_preds</th>\n",
       "      <th>lgbm_v0_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Winner Match</th>\n",
       "      <td>0.07632</td>\n",
       "      <td>0.29354</td>\n",
       "      <td>0.28963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top 3 Set Match</th>\n",
       "      <td>0.00783</td>\n",
       "      <td>0.05871</td>\n",
       "      <td>0.05479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top 3 Exact Match</th>\n",
       "      <td>0.00196</td>\n",
       "      <td>0.00978</td>\n",
       "      <td>0.00978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   random_probs  winning_odd_preds  lgbm_v0_preds\n",
       "Winner Match            0.07632            0.29354        0.28963\n",
       "Top 3 Set Match         0.00783            0.05871        0.05479\n",
       "Top 3 Exact Match       0.00196            0.00978        0.00978"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_results = baseline_mean_results.copy()\n",
    "compare_results['lgbm_v0_preds'] = lgbmv0_results_df['lgbm_v0_preds']\n",
    "compare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d8faf00e-24d4-4a6f-8aa3-791a48ca07db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 2] [1 2 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Winner Match': 1.0, 'Top 3 Set Match': 1.0, 'Top 3 Exact Match': 0.0}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_true = np.array(\n",
    "    [4, 1, 3, 2, 5]\n",
    ")\n",
    "\n",
    "y_pred_proba = np.array(\n",
    "    [0.2, 0.6, 0.4, 0.3, 0.1]\n",
    ")\n",
    "\n",
    "y_pred_ranksort = np.argsort(y_pred_proba, axis=0)[::-1][0:3]\n",
    "y_true_ranksort = np.argsort(y_true, axis=0)[0:3]\n",
    "# y_pred_ranksort = np.argsort(y_pred_ranks, axis=0)[0:3]\n",
    "\n",
    "print(y_true_ranksort, y_pred_ranksort)\n",
    "evaluate_horse_race_positions(y_true, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f11e84a1-feb8-40fb-af60-da81888090a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 3, 2, 1])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_ranks = np.argsort(y_pred_proba)\n",
    "y_pred_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "59514f63-ffd0-43dc-8c43-79b7567616ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 0, 4])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(y_pred_proba)[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b39cc8-1d28-4560-a3fa-b3be528fbdb8",
   "metadata": {},
   "source": [
    "# ad-hoc data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a7e3e04-2543-44b3-8848-616b437ee47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['finishing_position', 'horse_number', 'horse_name', 'horse_id', 'jockey', 'trainer', 'actual_weight', 'declared_horse_weight', 'draw', 'length_behind_winner', 'running_position_1', 'running_position_2', 'running_position_3', 'running_position_4', 'finish_time', 'win_odds', 'running_position_5', 'running_position_6', 'race_id', 'clean_actual_weight', 'clean_declared_horse_weight', 'clean_length_behind_winner', 'clean_finish_time', 'clean_win_odds', 'clean_position', 'is_winner', 'is_top3', 'src', 'race_date', 'race_course', 'race_number', 'race_class', 'race_distance', 'track_condition', 'race_name', 'track', 'sectional_time', 'incident_report', 'race_course_track', 'clean_race_date', 'clean_position_mavg_3', 'clean_position_mavg_5', 'clean_position_mavg_7', 'year']\n"
     ]
    }
   ],
   "source": [
    "print(val_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19db2664-bd0a-43d6-8a14-49641c744cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_utils.analyze_dataframe(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df4d909-a64d-4274-897b-0c4fcf5c789e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb219343-e645-4fd2-9f6b-84f43d99c6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90206eb-93d7-4883-a4e8-7f3171f3f889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2497435-9ca8-4010-b36c-936453ddc0e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c63a160-2c11-4f5a-91b1-7ce6604ff57b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358ac490-6ba9-40fc-a355-42388c3234cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py310] *",
   "language": "python",
   "name": "conda-env-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
