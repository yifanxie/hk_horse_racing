{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a35c2295-3ba9-4ca2-8693-408f8fa39cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from typing import Optional\n",
    "import glob\n",
    "from scipy import stats\n",
    "# Add the parent directory of this notebook to sys.path\n",
    "notebook_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from project_tools import project_utils, project_class\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "# import ds_utils\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, ndcg_score\n",
    "from scipy.stats import kendalltau, spearmanr\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "\n",
    "from importlib import reload\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.0f' % x)\n",
    "\n",
    "# Or for more precise control\n",
    "pd.set_option('display.float_format', '{:.5f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30285094-f3d9-4f6f-bf31-8724ff557cbe",
   "metadata": {},
   "source": [
    "# evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03db3907-2c6a-4e3d-b77e-8c6ab6390e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_horse_race_positions(y_true, y_pred_proba, dnf_value=99):\n",
    "    \"\"\"\n",
    "    Evaluate predictions for a single race's finishing positions.\n",
    "    \n",
    "    Args:\n",
    "        y_true: 1D array of true finishing positions\n",
    "        y_pred_proba: 1D array of predicted probabilities\n",
    "        dnf_value: Value used to indicate Did Not Finish\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    # Handle NaN and DNF values in ground truth\n",
    "    y_true_processed = y_true.copy()\n",
    "    invalid_mask = np.logical_or(\n",
    "        np.isnan(y_true),\n",
    "        y_true == dnf_value\n",
    "    )\n",
    "    \n",
    "    # Get max valid rank (excluding DNF values)\n",
    "    valid_ranks = y_true[~invalid_mask]\n",
    "    if len(valid_ranks) > 0:\n",
    "        max_rank = np.max(valid_ranks)\n",
    "        # Replace invalid values with max_rank + 1\n",
    "        y_true_processed[invalid_mask] = max_rank + 1\n",
    "        \n",
    "    # Winner match\n",
    "    y_true_ranksort = np.argsort(y_true_processed)\n",
    "    y_pred_ranksort = np.argsort(y_pred_proba, axis=0)[::-1]\n",
    "    \n",
    "    winner_match = y_true_ranksort[0] == y_pred_ranksort[0]\n",
    "    \n",
    "    # Top 3 Set Match - considers [1,3,2] and [2,3,1] as matching\n",
    "    top3_set_match = set(y_true_ranksort[:3]) == set(y_pred_ranksort[:3])\n",
    "    \n",
    "    # Top 3 Exact Match - only considers exact matches like [1,3,2] and [1,3,2]\n",
    "    top3_exact_match = np.array_equal(y_true_ranksort[:3], y_pred_ranksort[:3])\n",
    "    \n",
    "    return {\n",
    "        'Winner Match': float(winner_match),\n",
    "        'Top 3 Set Match': float(top3_set_match), \n",
    "        'Top 3 Exact Match': float(top3_exact_match)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35cb1557-0da1-4b7b-ba15-f787ebeaa510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "def evaluate_prediction_sets(eval_dict):\n",
    "    \"\"\"\n",
    "    Evaluate different prediction sets against ground truth for each race and calculate mean metrics\n",
    "    \n",
    "    Args:\n",
    "        eval_dict: Dictionary containing race data with ground truth and different prediction sets\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (eval_result, mean_results_df)\n",
    "            - eval_result: Dictionary with detailed evaluation metrics for each race\n",
    "            - mean_results_df: DataFrame comparing mean metrics across prediction types\n",
    "    \"\"\"\n",
    "    # Initialize results dictionary with race_ids as first level keys\n",
    "    eval_result = {race_id: {} for race_id in eval_dict}\n",
    "\n",
    "    # Get prediction types from first race data\n",
    "    first_race_id = next(iter(eval_dict))\n",
    "    pred_types = [key for key in eval_dict[first_race_id].keys() if key != 'ground_truth']\n",
    "\n",
    "    # Initialize dictionaries to store mean results\n",
    "    mean_results = {pred_type: {} for pred_type in pred_types}\n",
    "\n",
    "    # Loop through each race\n",
    "    for race_id in eval_dict:\n",
    "        race_data = eval_dict[race_id]\n",
    "        ground_truth = race_data['ground_truth']\n",
    "        \n",
    "        # Evaluate each prediction type\n",
    "        for pred_type in pred_types:\n",
    "            pred_probs = race_data[pred_type]\n",
    "            \n",
    "            # Evaluate predictions for this race\n",
    "            race_eval = evaluate_horse_race_positions(\n",
    "                ground_truth,\n",
    "                pred_probs\n",
    "            )\n",
    "            \n",
    "            # Store results for this race under race_id first, then pred_type\n",
    "            eval_result[race_id][pred_type] = race_eval\n",
    "\n",
    "    # Calculate mean results for each prediction type\n",
    "    for pred_type in pred_types:\n",
    "        # Initialize dict to store means for each metric\n",
    "        metric_means = {}\n",
    "        \n",
    "        # Get metrics from first race to know what metrics exist\n",
    "        first_race = next(iter(eval_result.values()))\n",
    "        metrics = first_race[pred_type].keys()\n",
    "        \n",
    "        # For each metric, calculate mean across all races\n",
    "        for metric in metrics:\n",
    "            total = 0\n",
    "            num_races = 0\n",
    "            for race_id in eval_result:\n",
    "                total += eval_result[race_id][pred_type][metric]\n",
    "                num_races += 1\n",
    "            metric_means[metric] = total / num_races\n",
    "            \n",
    "        mean_results[pred_type] = metric_means\n",
    "    \n",
    "    # Convert mean results to DataFrame for easy comparison\n",
    "    mean_results_df = pd.DataFrame(mean_results)\n",
    "    \n",
    "    return eval_result, mean_results_df\n",
    "\n",
    "# # Run evaluation\n",
    "# eval_result, mean_results_df = evaluate_prediction_sets(eval_dict)\n",
    "\n",
    "# # Display mean results comparison\n",
    "# print(\"\\nMean Evaluation Metrics Comparison:\")\n",
    "# print(mean_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7435ed7f-ac11-4540-856a-a711970185c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lightgbm_ranker(train_df, val_df=None, race_id_col='race_id', label_col='clean_position', \n",
    "                         cat_features=None, params=None, n_estimators=300):\n",
    "    \"\"\"\n",
    "    Train a LightGBM ranking model for horse race position prediction.\n",
    "    \n",
    "    Args:\n",
    "        train_df: Training DataFrame with features and labels\n",
    "        val_df: Optional validation DataFrame with features and labels\n",
    "        race_id_col: Column name for race identifier\n",
    "        label_col: Column name containing position/rank labels\n",
    "        cat_features: List of categorical feature names\n",
    "        params: LightGBM parameters dict\n",
    "        n_estimators: Number of boosting rounds\n",
    "        \n",
    "    Returns:\n",
    "        Trained model and validation predictions (if val_df provided)\n",
    "    \"\"\"\n",
    "    # Default ranking parameters if none provided\n",
    "    if params is None:\n",
    "        params = {\n",
    "            'objective': 'lambdarank',\n",
    "            'metric': 'ndcg',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': -1,\n",
    "            'max_position': 20,  # Maximum number of positions to consider\n",
    "            'label_gain': list(range(20)), # Gain for each position 0-19\n",
    "        }\n",
    "\n",
    "    # Prepare features and group info\n",
    "    features = [col for col in train_df.columns if col not in [label_col, race_id_col]]\n",
    "    X_train = train_df[features]\n",
    "    y_train = train_df[label_col]\n",
    "    # Convert positions to gains (lower position = higher gain)\n",
    "    max_pos = y_train.max()\n",
    "    y_train = max_pos - y_train + 1\n",
    "    \n",
    "    # Get group sizes for training data\n",
    "    train_groups = train_df.groupby(race_id_col).size().values\n",
    "\n",
    "    # Create training dataset\n",
    "    train_dataset = lgb.Dataset(\n",
    "        X_train, \n",
    "        label=y_train,\n",
    "        group=train_groups,\n",
    "        categorical_feature=cat_features if cat_features else 'auto'\n",
    "    )\n",
    "    \n",
    "    # Prepare validation data if provided\n",
    "    if val_df is not None:\n",
    "        X_val = val_df[features]\n",
    "        y_val = val_df[label_col]\n",
    "        y_val = max_pos - y_val + 1\n",
    "        val_groups = val_df.groupby(race_id_col).size().values\n",
    "        \n",
    "        val_dataset = lgb.Dataset(\n",
    "            X_val,\n",
    "            label=y_val, \n",
    "            group=val_groups,\n",
    "            reference=train_dataset,\n",
    "            categorical_feature=cat_features if cat_features else 'auto'\n",
    "        )\n",
    "        valid_sets = [val_dataset]\n",
    "    else:\n",
    "        valid_sets = None\n",
    "        X_val = None\n",
    "\n",
    "    # Train model\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_dataset,\n",
    "        num_boost_round=n_estimators,\n",
    "        valid_sets=None,\n",
    "        # verbose_eval=100 if val_df is not None else -1\n",
    "    )\n",
    "    \n",
    "    # Get validation predictions if validation data was provided\n",
    "    val_preds = model.predict(X_val) if val_df is not None else None\n",
    "    \n",
    "    return model, val_preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6982f56f-b2db-4040-91e8-698150c3078c",
   "metadata": {},
   "source": [
    "# load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffe699ef-d57e-45a2-9c00-1ac60118ce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_race_df = pd.read_parquet('../feature_data/horse_race_df.parquet')\n",
    "horse_race_df = horse_race_df.sort_values(by=['clean_race_date','race_id'], ascending=True).reset_index(drop=True)\n",
    "basic_cat_ordinal_df = pd.read_parquet('../feature_data/basic_cat_ordinal_features.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a823f28d-bc68-4e7f-830f-4a91c3ba815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_race_df = horse_race_df.sort_values(by=['clean_race_date','race_id'], ascending=True).reset_index(drop=True)\n",
    "horse_race_df['horse_jockey'] = horse_race_df['horse_id'] + '_' + horse_race_df['jockey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a886a6b-98df-4691-b0a7-bc5e95656322",
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_feats = pd.DataFrame()\n",
    "horse_feats['awght_dwght_ratio'] = horse_race_df['clean_actual_weight'] / horse_race_df['clean_declared_horse_weight']\n",
    "horse_feats['awght_dwght_delta'] = horse_race_df['clean_actual_weight'] - horse_race_df['clean_declared_horse_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39079e19-d117-445f-a6e8-0db5296f038d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_id</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>clean_race_date</th>\n",
       "      <th>clean_position</th>\n",
       "      <th>draw</th>\n",
       "      <th>horse_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11933</th>\n",
       "      <td>2015-178</td>\n",
       "      <td>T348</td>\n",
       "      <td>20151114</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11934</th>\n",
       "      <td>2015-178</td>\n",
       "      <td>S358</td>\n",
       "      <td>20151114</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11935</th>\n",
       "      <td>2015-178</td>\n",
       "      <td>S419</td>\n",
       "      <td>20151114</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11936</th>\n",
       "      <td>2015-178</td>\n",
       "      <td>T432</td>\n",
       "      <td>20151114</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11937</th>\n",
       "      <td>2015-178</td>\n",
       "      <td>S247</td>\n",
       "      <td>20151114</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11938</th>\n",
       "      <td>2015-178</td>\n",
       "      <td>T167</td>\n",
       "      <td>20151114</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11939</th>\n",
       "      <td>2015-178</td>\n",
       "      <td>T196</td>\n",
       "      <td>20151114</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11940</th>\n",
       "      <td>2015-178</td>\n",
       "      <td>S104</td>\n",
       "      <td>20151114</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>13.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11941</th>\n",
       "      <td>2015-178</td>\n",
       "      <td>P351</td>\n",
       "      <td>20151114</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>14.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11942</th>\n",
       "      <td>2015-178</td>\n",
       "      <td>T397</td>\n",
       "      <td>20151114</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11943</th>\n",
       "      <td>2015-178</td>\n",
       "      <td>T202</td>\n",
       "      <td>20151114</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>11.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11944</th>\n",
       "      <td>2015-178</td>\n",
       "      <td>N360</td>\n",
       "      <td>20151114</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>12.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11945</th>\n",
       "      <td>2015-178</td>\n",
       "      <td>T289</td>\n",
       "      <td>20151114</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>9.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11946</th>\n",
       "      <td>2015-178</td>\n",
       "      <td>T418</td>\n",
       "      <td>20151114</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        race_id horse_id  clean_race_date  clean_position  draw  horse_number\n",
       "11933  2015-178     T348         20151114               1     9       7.00000\n",
       "11934  2015-178     S358         20151114               2     1      10.00000\n",
       "11935  2015-178     S419         20151114               3    12       2.00000\n",
       "11936  2015-178     T432         20151114               4     7       6.00000\n",
       "11937  2015-178     S247         20151114               5     8       3.00000\n",
       "11938  2015-178     T167         20151114               6     6       5.00000\n",
       "11939  2015-178     T196         20151114               7    14       1.00000\n",
       "11940  2015-178     S104         20151114               8     4      13.00000\n",
       "11941  2015-178     P351         20151114               9    13      14.00000\n",
       "11942  2015-178     T397         20151114              10     2       8.00000\n",
       "11943  2015-178     T202         20151114              11     5      11.00000\n",
       "11944  2015-178     N360         20151114              12    10      12.00000\n",
       "11945  2015-178     T289         20151114              13    11       9.00000\n",
       "11946  2015-178     T418         20151114              14     3       4.00000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rid = horse_race_df['race_id'].sample(1).values[0]\n",
    "use_cols = ['race_id','horse_id', 'clean_race_date', 'clean_position', 'draw', 'horse_number']\n",
    "horse_race_df[horse_race_df['race_id']==rid][use_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4f54b113-5c9b-424d-9c93-d2f5eb3c911e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jockey',\n",
       " 'trainer',\n",
       " 'race_course',\n",
       " 'race_course_track',\n",
       " 'race_class',\n",
       " 'track_condition',\n",
       " 'horse_jockey']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_num_features = ['horse_number', 'clean_actual_weight', 'clean_declared_horse_weight',\n",
    "                  'clean_win_odds', 'race_distance']\n",
    "\n",
    "\n",
    "basic_cat_features = basic_cat_ordinal_df.columns.tolist() + ['horse_jockey']\n",
    "basic_cat_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "969e22f1-b86d-4881-8a7e-3f1a68d5adca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29520, 7) (29520, 41) (29520, 7)\n"
     ]
    }
   ],
   "source": [
    "# label_encoding\n",
    "lbl_enc = project_class.DataFrameLabelTransformer()\n",
    "race_enc_df = lbl_enc.fit_transform(horse_race_df[['race_id']].copy())\n",
    "\n",
    "# binary encoding\n",
    "lbl_enc = project_class.DataFrameLabelTransformer()\n",
    "lbl_df = lbl_enc.fit_transform(horse_race_df[basic_cat_features].copy())\n",
    "\n",
    "binary_enc = project_class.DataFrameBinaryEncoder(cat_cols=basic_cat_features,  verbose=False)\n",
    "bin_df = binary_enc.fit_transform(lbl_df)\n",
    "\n",
    "freq_df = project_utils.freq_encoding(lbl_df)\n",
    "\n",
    "print(lbl_df.shape, bin_df.shape,freq_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0e5764f6-4358-4119-b6e6-578308935a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jockey_bin_0', 'jockey_bin_1', 'jockey_bin_2', 'jockey_bin_3', 'jockey_bin_4', 'jockey_bin_5', 'jockey_bin_6', 'trainer_bin_0', 'trainer_bin_1', 'trainer_bin_2', 'trainer_bin_3', 'trainer_bin_4', 'trainer_bin_5', 'trainer_bin_6', 'race_course_bin_0', 'race_course_track_bin_0', 'race_course_track_bin_1', 'race_course_track_bin_2', 'race_course_track_bin_3', 'race_class_bin_0', 'race_class_bin_1', 'race_class_bin_2', 'race_class_bin_3', 'track_condition_bin_0', 'track_condition_bin_1', 'track_condition_bin_2', 'track_condition_bin_3', 'horse_jockey_bin_0', 'horse_jockey_bin_1', 'horse_jockey_bin_2', 'horse_jockey_bin_3', 'horse_jockey_bin_4', 'horse_jockey_bin_5', 'horse_jockey_bin_6', 'horse_jockey_bin_7', 'horse_jockey_bin_8', 'horse_jockey_bin_9', 'horse_jockey_bin_10', 'horse_jockey_bin_11', 'horse_jockey_bin_12', 'horse_jockey_bin_13']\n"
     ]
    }
   ],
   "source": [
    "print(bin_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "be924fb2-0c28-4636-9fea-275b35c69307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['jockey_freq', 'trainer_freq', 'race_course_freq',\n",
       "       'race_course_track_freq', 'race_class_freq', 'track_condition_freq',\n",
       "       'horse_jockey_freq'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309a924b-3913-4f75-9e50-bd497f87f64b",
   "metadata": {},
   "source": [
    "# horse weight delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad7eca24-229e-4111-a3b1-72b1b8d5afee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weight_delta(df, horse_id_col, weight_col):\n",
    "    \"\"\"\n",
    "    Calculate weight change between consecutive races for each horse.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing horse race data\n",
    "        horse_id_col: Column name containing horse IDs\n",
    "        weight_col: Column name containing horse weights\n",
    "        \n",
    "    Returns:\n",
    "        Numpy array containing weight deltas between consecutive races.\n",
    "        For first race of each horse, delta will be NaN.\n",
    "    \"\"\"\n",
    "    # Create array to store deltas, initialize with NaN\n",
    "    weight_deltas = np.full(len(df), np.nan)\n",
    "    \n",
    "    # Get unique horses\n",
    "    horses = df[horse_id_col].unique()\n",
    "    \n",
    "    # Calculate weight delta for each horse\n",
    "    for horse in horses:\n",
    "        # Get all races for this horse in chronological order\n",
    "        horse_mask = df[horse_id_col] == horse\n",
    "        horse_data = df[horse_mask].copy()\n",
    "        \n",
    "        if len(horse_data) > 1:  # Only calculate if horse has multiple races\n",
    "            # Get weight values\n",
    "            weights = horse_data[weight_col].values\n",
    "            \n",
    "            # Calculate deltas between consecutive races\n",
    "            deltas = weights[1:] - weights[:-1]\n",
    "            \n",
    "            # Store deltas in result array, skipping first race\n",
    "            horse_indices = horse_data.index[1:]  # Indices for all races except first\n",
    "            weight_deltas[horse_indices] = deltas\n",
    "            \n",
    "    return weight_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99e0de4e-3a31-490c-8f05-1c934ad76ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "horse_dweight_delta = calculate_weight_delta(horse_race_df, 'horse_id','clean_declared_horse_weight')\n",
    "horse_aweight_delta = calculate_weight_delta(horse_race_df, 'horse_id','clean_actual_weight')\n",
    "\n",
    "horse_weigh_feats_df = pd.DataFrame(horse_race_df['horse_id'])\n",
    "horse_weigh_feats_df['dweight_delta'] = horse_dweight_delta\n",
    "horse_weigh_feats_df['aweight_delta'] = horse_aweight_delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9519c9bf-484d-49c0-b1c1-dc81c38a64b5",
   "metadata": {},
   "source": [
    "# horse race inteval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2db9e35e-1e32-4128-b627-66ee244bcef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_feature_delta(df, id_col, feat_col):\n",
    "\n",
    "    # Create array to store deltas, initialize with NaN\n",
    "    feature_deltas = np.full(len(df), np.nan)\n",
    "    \n",
    "    # Get unique horses\n",
    "    ids = df[id_col].unique()\n",
    "    # print(len(ids))\n",
    "    # Calculate weight delta for each horse\n",
    "    for tid in ids :\n",
    "        # Get all races for this horse in chronological order\n",
    "        tid_mask = df[id_col] == tid\n",
    "        tid_data = df[tid_mask].copy()        \n",
    "        if len(tid_data) > 1:  # Only calculate if horse has multiple races\n",
    "            # Get weight values\n",
    "            values = tid_data[feat_col].values            \n",
    "            # Calculate deltas between consecutive races\n",
    "            deltas = values[1:] - values[:-1]            \n",
    "            # Store deltas in result array, skipping first race\n",
    "            tid_indices = tid_data.index[1:]  # Indices for all races except first\n",
    "            feature_deltas[tid_indices] = deltas            \n",
    "    return feature_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5907cf9b-9824-4b9b-b503-32cb6198766e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2155\n"
     ]
    }
   ],
   "source": [
    "horse_date_delta = calculate_feature_delta(horse_race_df, 'horse_id', 'clean_race_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "83b927c6-bf56-4ede-a645-0f2701de2e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    }
   ],
   "source": [
    "jockey_date_delta = calculate_feature_delta(horse_race_df, 'jockey', 'clean_race_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8bfee4e4-acd2-4186-a4fd-7735ad112b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "horse_jockey_date_delta = calculate_feature_delta(horse_race_df, 'horse_jockey', 'clean_race_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2276a0b6-a9f8-413f-922d-6eec9fa057f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_cols = ['race_id', 'horse_id', 'horse_jockey', 'jockey','clean_race_date', 'clean_position']\n",
    "feature_df = horse_race_df[key_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "132854f5-63e9-4251-8b54-09c6285692d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df['horse_date_delta'] = horse_date_delta\n",
    "feature_df['jockey_date_delta'] = jockey_date_delta\n",
    "feature_df['horse_jockey_date_delta'] = horse_jockey_date_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3ab71d92-e941-44a2-8a20-1c457d5b0b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_id</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>horse_jockey</th>\n",
       "      <th>jockey</th>\n",
       "      <th>clean_race_date</th>\n",
       "      <th>clean_position</th>\n",
       "      <th>horse_date_delta</th>\n",
       "      <th>jockey_date_delta</th>\n",
       "      <th>horse_jockey_date_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4322</th>\n",
       "      <td>2014-349</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20150128</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4630</th>\n",
       "      <td>2014-374</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20150207</td>\n",
       "      <td>8</td>\n",
       "      <td>79.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>79.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5498</th>\n",
       "      <td>2014-443</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20150308</td>\n",
       "      <td>8</td>\n",
       "      <td>101.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>101.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5843</th>\n",
       "      <td>2014-470</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20150318</td>\n",
       "      <td>1</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>10.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>2014-508</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20150401</td>\n",
       "      <td>2</td>\n",
       "      <td>83.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>83.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6914</th>\n",
       "      <td>2014-554</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20150422</td>\n",
       "      <td>2</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>21.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7978</th>\n",
       "      <td>2014-639</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20150524</td>\n",
       "      <td>3</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>102.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8577</th>\n",
       "      <td>2014-686</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20150610</td>\n",
       "      <td>1</td>\n",
       "      <td>86.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>86.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9169</th>\n",
       "      <td>2014-733</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20150627</td>\n",
       "      <td>7</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>17.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9717</th>\n",
       "      <td>2014-776</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20150712</td>\n",
       "      <td>10</td>\n",
       "      <td>85.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>85.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11539</th>\n",
       "      <td>2015-147</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20151101</td>\n",
       "      <td>4</td>\n",
       "      <td>178.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>389.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12259</th>\n",
       "      <td>2015-204</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20151125</td>\n",
       "      <td>2</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>24.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12499</th>\n",
       "      <td>2015-223</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20151202</td>\n",
       "      <td>1</td>\n",
       "      <td>77.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>77.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12918</th>\n",
       "      <td>2015-256</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20151216</td>\n",
       "      <td>2</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>14.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13599</th>\n",
       "      <td>2015-309</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20160106</td>\n",
       "      <td>6</td>\n",
       "      <td>8890.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>8890.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13828</th>\n",
       "      <td>2015-327</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20160113</td>\n",
       "      <td>6</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14411</th>\n",
       "      <td>2015-373</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20160203</td>\n",
       "      <td>11</td>\n",
       "      <td>90.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>90.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18760</th>\n",
       "      <td>2015-722</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20160615</td>\n",
       "      <td>5</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>412.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19220</th>\n",
       "      <td>2015-759</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20160701</td>\n",
       "      <td>5</td>\n",
       "      <td>86.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>86.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19992</th>\n",
       "      <td>2016-035</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20160918</td>\n",
       "      <td>13</td>\n",
       "      <td>217.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>217.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20518</th>\n",
       "      <td>2016-078</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20161005</td>\n",
       "      <td>6</td>\n",
       "      <td>87.00000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>87.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21037</th>\n",
       "      <td>2016-120</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20161019</td>\n",
       "      <td>8</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>14.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21516</th>\n",
       "      <td>2016-160</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20161106</td>\n",
       "      <td>8</td>\n",
       "      <td>87.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>87.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22289</th>\n",
       "      <td>2016-221</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20161127</td>\n",
       "      <td>12</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>21.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24433</th>\n",
       "      <td>2016-392</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20170205</td>\n",
       "      <td>8</td>\n",
       "      <td>9078.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>9078.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25254</th>\n",
       "      <td>2016-458</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20170301</td>\n",
       "      <td>11</td>\n",
       "      <td>96.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>96.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25909</th>\n",
       "      <td>2016-511</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20170322</td>\n",
       "      <td>6</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>21.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27720</th>\n",
       "      <td>2016-658</td>\n",
       "      <td>P120</td>\n",
       "      <td>P120_H W Lai</td>\n",
       "      <td>H W Lai</td>\n",
       "      <td>20170517</td>\n",
       "      <td>7</td>\n",
       "      <td>195.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>195.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        race_id horse_id  horse_jockey   jockey  clean_race_date  \\\n",
       "4322   2014-349     P120  P120_H W Lai  H W Lai         20150128   \n",
       "4630   2014-374     P120  P120_H W Lai  H W Lai         20150207   \n",
       "5498   2014-443     P120  P120_H W Lai  H W Lai         20150308   \n",
       "5843   2014-470     P120  P120_H W Lai  H W Lai         20150318   \n",
       "6332   2014-508     P120  P120_H W Lai  H W Lai         20150401   \n",
       "6914   2014-554     P120  P120_H W Lai  H W Lai         20150422   \n",
       "7978   2014-639     P120  P120_H W Lai  H W Lai         20150524   \n",
       "8577   2014-686     P120  P120_H W Lai  H W Lai         20150610   \n",
       "9169   2014-733     P120  P120_H W Lai  H W Lai         20150627   \n",
       "9717   2014-776     P120  P120_H W Lai  H W Lai         20150712   \n",
       "11539  2015-147     P120  P120_H W Lai  H W Lai         20151101   \n",
       "12259  2015-204     P120  P120_H W Lai  H W Lai         20151125   \n",
       "12499  2015-223     P120  P120_H W Lai  H W Lai         20151202   \n",
       "12918  2015-256     P120  P120_H W Lai  H W Lai         20151216   \n",
       "13599  2015-309     P120  P120_H W Lai  H W Lai         20160106   \n",
       "13828  2015-327     P120  P120_H W Lai  H W Lai         20160113   \n",
       "14411  2015-373     P120  P120_H W Lai  H W Lai         20160203   \n",
       "18760  2015-722     P120  P120_H W Lai  H W Lai         20160615   \n",
       "19220  2015-759     P120  P120_H W Lai  H W Lai         20160701   \n",
       "19992  2016-035     P120  P120_H W Lai  H W Lai         20160918   \n",
       "20518  2016-078     P120  P120_H W Lai  H W Lai         20161005   \n",
       "21037  2016-120     P120  P120_H W Lai  H W Lai         20161019   \n",
       "21516  2016-160     P120  P120_H W Lai  H W Lai         20161106   \n",
       "22289  2016-221     P120  P120_H W Lai  H W Lai         20161127   \n",
       "24433  2016-392     P120  P120_H W Lai  H W Lai         20170205   \n",
       "25254  2016-458     P120  P120_H W Lai  H W Lai         20170301   \n",
       "25909  2016-511     P120  P120_H W Lai  H W Lai         20170322   \n",
       "27720  2016-658     P120  P120_H W Lai  H W Lai         20170517   \n",
       "\n",
       "       clean_position  horse_date_delta  jockey_date_delta  \\\n",
       "4322                6               NaN            0.00000   \n",
       "4630                8          79.00000            0.00000   \n",
       "5498                8         101.00000            0.00000   \n",
       "5843                1          10.00000            0.00000   \n",
       "6332                2          83.00000            0.00000   \n",
       "6914                2          21.00000            0.00000   \n",
       "7978                3          18.00000            0.00000   \n",
       "8577                1          86.00000            0.00000   \n",
       "9169                7          17.00000            0.00000   \n",
       "9717               10          85.00000            0.00000   \n",
       "11539               4         178.00000            0.00000   \n",
       "12259               2          24.00000            0.00000   \n",
       "12499               1          77.00000            0.00000   \n",
       "12918               2          14.00000            0.00000   \n",
       "13599               6        8890.00000            0.00000   \n",
       "13828               6           7.00000            0.00000   \n",
       "14411              11          90.00000            0.00000   \n",
       "18760               5          14.00000            0.00000   \n",
       "19220               5          86.00000            0.00000   \n",
       "19992              13         217.00000            0.00000   \n",
       "20518               6          87.00000            4.00000   \n",
       "21037               8          14.00000            0.00000   \n",
       "21516               8          87.00000            0.00000   \n",
       "22289              12          21.00000            0.00000   \n",
       "24433               8        9078.00000            0.00000   \n",
       "25254              11          96.00000            0.00000   \n",
       "25909               6          21.00000            0.00000   \n",
       "27720               7         195.00000            0.00000   \n",
       "\n",
       "       horse_jockey_date_delta  \n",
       "4322                       NaN  \n",
       "4630                  79.00000  \n",
       "5498                 101.00000  \n",
       "5843                  10.00000  \n",
       "6332                  83.00000  \n",
       "6914                  21.00000  \n",
       "7978                 102.00000  \n",
       "8577                  86.00000  \n",
       "9169                  17.00000  \n",
       "9717                  85.00000  \n",
       "11539                389.00000  \n",
       "12259                 24.00000  \n",
       "12499                 77.00000  \n",
       "12918                 14.00000  \n",
       "13599               8890.00000  \n",
       "13828                  7.00000  \n",
       "14411                 90.00000  \n",
       "18760                412.00000  \n",
       "19220                 86.00000  \n",
       "19992                217.00000  \n",
       "20518                 87.00000  \n",
       "21037                 14.00000  \n",
       "21516                 87.00000  \n",
       "22289                 21.00000  \n",
       "24433               9078.00000  \n",
       "25254                 96.00000  \n",
       "25909                 21.00000  \n",
       "27720                195.00000  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df[feature_df['horse_jockey']=='P120_H W Lai']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dd554e52-eab0-4c5a-99ca-1ac6a22cde5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13959"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df['horse_jockey'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9fb351-f584-4383-ae9e-d3d585d9acc4",
   "metadata": {},
   "source": [
    "# run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "95c87c73-4a6b-4901-afea-86bbf3dc9d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29520, 53)\n"
     ]
    }
   ],
   "source": [
    "# rank model benchmark features\n",
    "df0 = pd.concat([horse_race_df[basic_num_features]], axis=1)\n",
    "df0['race_id'] = race_enc_df['race_id']\n",
    "\n",
    "horse_weight_delta_feats = ['dweight_delta', 'aweight_delta']\n",
    "df1 = pd.concat([df0, lbl_df,  bin_df, freq_df, horse_feats, \n",
    "                 horse_weigh_feats_df[horse_weight_delta_feats]], axis=1)\n",
    "\n",
    "\n",
    "key_cols = ['race_id', 'horse_id', 'horse_jockey', 'jockey','clean_race_date', 'clean_position']\n",
    "feature_cols = [c for c in feature_df.columns if c not in key_cols]\n",
    "df2 = pd.concat([df1, feature_df[feature_cols]], axis=1)\n",
    "\n",
    "remove_cols = [c for c in df2.columns if 'horse_jockey_bin' in c]\n",
    "remove_cols += ['horse_number']\n",
    "df2 = df2.drop(remove_cols, axis=1)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "40758de6-8a21-45e7-8ac2-5f95c0b1e659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jockey', 'trainer', 'race_course', 'race_course_track', 'race_class', 'track_condition', 'horse_jockey']\n",
      "['clean_actual_weight', 'clean_declared_horse_weight', 'clean_win_odds', 'race_distance', 'race_id', 'jockey', 'trainer', 'race_course', 'race_course_track', 'race_class', 'track_condition', 'horse_jockey', 'jockey_bin_0', 'jockey_bin_1', 'jockey_bin_2', 'jockey_bin_3', 'jockey_bin_4', 'jockey_bin_5', 'jockey_bin_6', 'trainer_bin_0', 'trainer_bin_1', 'trainer_bin_2', 'trainer_bin_3', 'trainer_bin_4', 'trainer_bin_5', 'trainer_bin_6', 'race_course_bin_0', 'race_course_track_bin_0', 'race_course_track_bin_1', 'race_course_track_bin_2', 'race_course_track_bin_3', 'race_class_bin_0', 'race_class_bin_1', 'race_class_bin_2', 'race_class_bin_3', 'track_condition_bin_0', 'track_condition_bin_1', 'track_condition_bin_2', 'track_condition_bin_3', 'jockey_freq', 'trainer_freq', 'race_course_freq', 'race_course_track_freq', 'race_class_freq', 'track_condition_freq', 'horse_jockey_freq', 'awght_dwght_ratio', 'awght_dwght_delta', 'dweight_delta', 'aweight_delta', 'horse_date_delta', 'jockey_date_delta', 'horse_jockey_date_delta']\n"
     ]
    }
   ],
   "source": [
    "run_df = df2.copy()\n",
    "# train_df = run_df.loc[train_idx].reset_index(drop=True)\n",
    "# # train_df = train_df.loc[int(len(train_df)/2), len(train_df)]\n",
    "# val_df = run_df.loc[val_idx]\n",
    "\n",
    "\n",
    "params = {\n",
    "    'objective': 'lambdarank',\n",
    "    'metric': 'ndcg',\n",
    "    'boosting_type': 'gbdt',\n",
    "    # 'n_estimators':300,\n",
    "    'num_leaves': 32,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.8,  # Column sampling\n",
    "    'bagging_fraction': 0.8,  # Row sampling \n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1,\n",
    "    'max_position': 20,  # Maximum number of positions to consider\n",
    "    'label_gain': list(range(20))\n",
    "}\n",
    "\n",
    "target1 = 'clean_position'\n",
    "# target2 = 'is_top3'\n",
    "basic_cat_features = basic_cat_ordinal_df.columns.tolist() + ['horse_jockey']\n",
    "use_cats = [c for c in run_df.columns if c in basic_cat_features]\n",
    "print(use_cats)\n",
    "\n",
    "df_rank = run_df.copy()\n",
    "df_rank[target1] = horse_race_df[target1]\n",
    "# df_rank = df_rank[df_rank['clean_position']!=99].reset_index(drop=True)\n",
    "\n",
    "feature_names = [c for c in run_df.columns if c not in [target1]]\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e5af6fe6-9494-453e-adea-80ca0b72bea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23232 6288\n",
      "(23231, 54) (6288, 54)\n",
      "building model for target - clean_position\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_years = ['2014','2015','2016']\n",
    "val_years = ['2017']\n",
    "train_idx = horse_race_df[horse_race_df['year'].isin(train_years)].index\n",
    "val_idx = horse_race_df[horse_race_df['year'].isin(val_years)].index\n",
    "print(len(train_idx), len(val_idx))\n",
    "\n",
    "train_df = df_rank.loc[train_idx]\n",
    "train_df = train_df[train_df['clean_position']!=99].reset_index(drop=True)\n",
    "# train_df = train_df.loc[int(len(train_df)/2), len(train_df)-1]\n",
    "# start_idx = int((len(train_df)/10)*2)\n",
    "# train_df = train_df.loc[start_idx:]\n",
    "val_df = df_rank.loc[val_idx]\n",
    "\n",
    "group_col = 'race_id'\n",
    "print(train_df.shape, val_df.shape)\n",
    "\n",
    "print(f'building model for target - {target1}')\n",
    "model_rank, val_rank_preds = train_lightgbm_ranker(train_df, val_df, group_col, target1,\n",
    "                                        cat_features=use_cats, params=params, \n",
    "                                        n_estimators=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2d7ca4-d360-4d31-a24e-3bc42e083e12",
   "metadata": {},
   "source": [
    "## model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a5b9d0a6-e687-4116-89b6-115c35c3a924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgbm_v1_preds_ranker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Winner Match</th>\n",
       "      <td>0.29354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top 3 Set Match</th>\n",
       "      <td>0.08023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top 3 Exact Match</th>\n",
       "      <td>0.01761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   lgbm_v1_preds_ranker\n",
       "Winner Match                    0.29354\n",
       "Top 3 Set Match                 0.08023\n",
       "Top 3 Exact Match               0.01761"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_horse_race_df = horse_race_df.loc[val_idx].reset_index(drop=True)\n",
    "pred_col  = f'lgbm_v1_preds_ranker'\n",
    "val_horse_race_df[pred_col] = val_rank_preds\n",
    "\n",
    "eval_dict = {}\n",
    "ground_truth = {}\n",
    "\n",
    "for race in val_horse_race_df['race_id'].unique():\n",
    "    race_df = val_horse_race_df[val_horse_race_df['race_id']==race]\n",
    "    n_horse = race_df.shape[0]    \n",
    "    eval_dict[race] = {}\n",
    "    eval_dict[race]['ground_truth'] = race_df['clean_position'].values\n",
    "    eval_dict[race][pred_col] = race_df[pred_col].values\n",
    "\n",
    "\n",
    "eval_result, lgbmv1_rank_results_df = evaluate_prediction_sets(eval_dict)\n",
    "lgbmv1_rank_results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "54610811-916e-42f3-b0e7-8a283b6be128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random_probs</th>\n",
       "      <th>winning_odd_preds</th>\n",
       "      <th>lgbm_v1_preds_ranker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Winner Match</th>\n",
       "      <td>0.07632</td>\n",
       "      <td>0.29354</td>\n",
       "      <td>0.29354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top 3 Set Match</th>\n",
       "      <td>0.00783</td>\n",
       "      <td>0.05871</td>\n",
       "      <td>0.08023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top 3 Exact Match</th>\n",
       "      <td>0.00196</td>\n",
       "      <td>0.00978</td>\n",
       "      <td>0.01761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   random_probs  winning_odd_preds  lgbm_v1_preds_ranker\n",
       "Winner Match            0.07632            0.29354               0.29354\n",
       "Top 3 Set Match         0.00783            0.05871               0.08023\n",
       "Top 3 Exact Match       0.00196            0.00978               0.01761"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_mean_results = pd.read_parquet('../evaluation_results/valdf_random_winodd_baseline_mean_results.parquet')\n",
    "compare_results = baseline_mean_results.copy()\n",
    "compare_results[pred_col_rank] = lgbmv1_rank_results_df\n",
    "compare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390ee58f-3b56-41e1-9429-51af90a1ecd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93b1f34e-b5d7-4c28-83aa-77fd9565b291",
   "metadata": {},
   "source": [
    "# avg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e8b0d6ff-39b9-47a6-a091-e49245de018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_pred = pd.read_parquet('../feature_data/model_results/val_results_lgbm_pairwise.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9b25a6dd-b56a-424b-94f8-fe9e104fbb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_pred_vals = pairwise_pred['prediction'].rank(pct=True).values\n",
    "rank_pred_vals = project_utils.get_rank(val_rank_preds)\n",
    "\n",
    "avg_df = val_horse_race_df[['race_id']].copy()\n",
    "avg_df['pw_preds'] = pairwise_pred_vals\n",
    "avg_df['rank_preds'] = rank_pred_vals\n",
    "avg_df['preds'] = project_utils.get_rank(((pairwise_pred_vals + rank_pred_vals)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5a9192d9-41f6-45ad-81d2-2a9d502039da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pw_rank_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Winner Match</th>\n",
       "      <td>0.30528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top 3 Set Match</th>\n",
       "      <td>0.07436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top 3 Exact Match</th>\n",
       "      <td>0.01957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   pw_rank_avg\n",
       "Winner Match           0.30528\n",
       "Top 3 Set Match        0.07436\n",
       "Top 3 Exact Match      0.01957"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_horse_race_df = horse_race_df.loc[val_idx].reset_index(drop=True)\n",
    "pred_col  = f'pw_rank_avg'\n",
    "val_horse_race_df[pred_col] = avg_df['preds']\n",
    "\n",
    "eval_dict = {}\n",
    "ground_truth = {}\n",
    "\n",
    "for race in val_horse_race_df['race_id'].unique():\n",
    "    race_df = val_horse_race_df[val_horse_race_df['race_id']==race]\n",
    "    n_horse = race_df.shape[0]    \n",
    "    eval_dict[race] = {}\n",
    "    eval_dict[race]['ground_truth'] = race_df['clean_position'].values\n",
    "    eval_dict[race][pred_col] = race_df[pred_col].values\n",
    "\n",
    "\n",
    "eval_result, pwrank_avg_results_df = evaluate_prediction_sets(eval_dict)\n",
    "pwrank_avg_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b337d7db-7bb2-4959-a95c-d40208a4903b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random_probs</th>\n",
       "      <th>winning_odd_preds</th>\n",
       "      <th>lgbm_v1_preds_ranker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Winner Match</th>\n",
       "      <td>0.07632</td>\n",
       "      <td>0.29354</td>\n",
       "      <td>0.30528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top 3 Set Match</th>\n",
       "      <td>0.00783</td>\n",
       "      <td>0.05871</td>\n",
       "      <td>0.07436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top 3 Exact Match</th>\n",
       "      <td>0.00196</td>\n",
       "      <td>0.00978</td>\n",
       "      <td>0.01957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   random_probs  winning_odd_preds  lgbm_v1_preds_ranker\n",
       "Winner Match            0.07632            0.29354               0.30528\n",
       "Top 3 Set Match         0.00783            0.05871               0.07436\n",
       "Top 3 Exact Match       0.00196            0.00978               0.01957"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_mean_results = pd.read_parquet('../evaluation_results/valdf_random_winodd_baseline_mean_results.parquet')\n",
    "compare_results = baseline_mean_results.copy()\n",
    "compare_results[pred_col_rank] = pwrank_avg_results_df\n",
    "compare_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87539270-a805-476e-a8b8-7a4544202e04",
   "metadata": {},
   "source": [
    "# time-progress prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b4f86bba-94db-4a1b-8e5f-6427fb467d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23231, 54) (6288, 54)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, val_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "4cf49c99-936f-44d9-a678-6fa523110cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_progressive_predictions(train_df, val_df, date_col='clean_race_date', \n",
    "                                       race_id_col='race_id', target_col='clean_position',\n",
    "                                        cat_features=None,\n",
    "                                       params = None,  n_estimators=300,\n",
    "                                       min_train_days=None, max_train_days=None,\n",
    "                                       save_models=False, model_dir=None,\n",
    "                                       verbose=True):\n",
    "    \"\"\"\n",
    "    Enhanced version with progress bar and additional features\n",
    "    \"\"\"\n",
    "    val_df = val_df.sort_values(date_col)\n",
    "    unique_dates = val_df[date_col].unique()\n",
    "    predictions_list = []\n",
    "    current_train_df = train_df.copy()\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Initial training set size: {len(current_train_df):,} rows\")\n",
    "        print(f\"Processing {len(unique_dates)} dates...\")\n",
    "        \n",
    "        if min_train_days or max_train_days:\n",
    "            print(f\"Training window: {min_train_days or 'None'} to {max_train_days or 'None'} days\")\n",
    "    \n",
    "    # Process each date with tqdm progress bar\n",
    "    for pred_date in tqdm(unique_dates, desc=\"Processing dates\"):\n",
    "        # Apply training window if specified\n",
    "        if min_train_days or max_train_days:\n",
    "            current_train_df['days_diff'] = (\n",
    "                pd.to_datetime(pred_date) - pd.to_datetime(current_train_df[date_col])\n",
    "            ).dt.days\n",
    "            \n",
    "            train_mask = True\n",
    "            if min_train_days:\n",
    "                train_mask &= current_train_df['days_diff'] >= min_train_days\n",
    "            if max_train_days:\n",
    "                train_mask &= current_train_df['days_diff'] <= max_train_days\n",
    "                \n",
    "            training_data = current_train_df[train_mask].drop('days_diff', axis=1)\n",
    "        else:\n",
    "            training_data = current_train_df\n",
    "        \n",
    "        # Get validation data for current date\n",
    "        current_val_mask = val_df[date_col] == pred_date\n",
    "        current_val_df = val_df[current_val_mask]\n",
    "        \n",
    "        # Train model and make predictions\n",
    "        model, current_pred_val = train_lightgbm_ranker(training_data, current_val_df, race_id_col, \n",
    "                           target_col, cat_features, params, n_estimators)\n",
    "        \n",
    "        # Save model if requested\n",
    "        # if save_models and model_dir:\n",
    "        #     os.makedirs(model_dir, exist_ok=True)\n",
    "        #     model_path = os.path.join(model_dir, f\"model_{pred_date}.txt\")\n",
    "        #     model.save_model(model_path)\n",
    "        \n",
    "        # Store predictions with metadata\n",
    "        current_preds = pd.DataFrame({\n",
    "            'original_index': current_val_df.index,\n",
    "            'predictions': current_pred_val,\n",
    "            'pred_date': pred_date,\n",
    "            'training_size': len(training_data)\n",
    "        })\n",
    "        predictions_list.append(current_preds)\n",
    "        \n",
    "        # Update training data\n",
    "        current_train_df = pd.concat([\n",
    "            current_train_df,\n",
    "            current_val_df\n",
    "        ]).reset_index(drop=True)\n",
    "    \n",
    "    # Combine and reorder predictions\n",
    "    all_predictions = pd.concat(predictions_list)\n",
    "    all_predictions = all_predictions.sort_values('original_index')\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\nPrediction Summary:\")\n",
    "        print(f\"Total predictions: {len(all_predictions):,}\")\n",
    "        print(f\"Dates processed: {len(unique_dates):,}\")\n",
    "        print(f\"Final training set size: {len(current_train_df):,}\")\n",
    "    \n",
    "    return all_predictions['predictions'].values, all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "d8c268f2-1d4b-406e-81d8-49f9bdd7dc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23232 6288\n",
      "(23231, 55) (6288, 55)\n",
      "building model for target - clean_position\n",
      "Initial training set size: 23,231 rows\n",
      "Processing 56 dates...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e051514f534af39cabca64d3c6dbc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing dates:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Summary:\n",
      "Total predictions: 6,288\n",
      "Dates processed: 56\n",
      "Final training set size: 29,519\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_years = ['2014','2015','2016']\n",
    "val_years = ['2017']\n",
    "train_idx = horse_race_df[horse_race_df['year'].isin(train_years)].index\n",
    "val_idx = horse_race_df[horse_race_df['year'].isin(val_years)].index\n",
    "print(len(train_idx), len(val_idx))\n",
    "\n",
    "df_rank = run_df.copy()\n",
    "df_rank['clean_race_date'] = horse_race_df['clean_race_date']\n",
    "df_rank['clean_position'] = horse_race_df['clean_position']\n",
    "train_df = df_rank.loc[train_idx]\n",
    "train_df = train_df[train_df['clean_position']!=99].reset_index(drop=True)\n",
    "# train_df = train_df.loc[int(len(train_df)/2), len(train_df)-1]\n",
    "# start_idx = int((len(train_df)/10)*2)\n",
    "# train_df = train_df.loc[start_idx:]\n",
    "val_df = df_rank.loc[val_idx]\n",
    "\n",
    "group_col = 'race_id'\n",
    "print(train_df.shape, val_df.shape)\n",
    "\n",
    "print(f'building model for target - {target1}')\n",
    "all_pred_vals, all_predictions = make_progressive_predictions(train_df, val_df, \n",
    "                                       date_col='clean_race_date', \n",
    "                                       race_id_col='race_id', target_col='clean_position',\n",
    "                                       cat_features=None,\n",
    "                                       params = None,  n_estimators=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "beb38738-3626-4cdd-9e95-a9772ea1a34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6288,)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pred_vals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "78a1e14d-91f1-41fc-a874-99a8a27c1a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgbrank_timeprog_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Winner Match</th>\n",
       "      <td>0.29159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top 3 Set Match</th>\n",
       "      <td>0.08219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top 3 Exact Match</th>\n",
       "      <td>0.00391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   lgbrank_timeprog_preds\n",
       "Winner Match                      0.29159\n",
       "Top 3 Set Match                   0.08219\n",
       "Top 3 Exact Match                 0.00391"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_horse_race_df = horse_race_df.loc[val_idx].reset_index(drop=True)\n",
    "pred_col  = f'lgbrank_timeprog_preds'\n",
    "val_horse_race_df[pred_col] = all_pred_vals\n",
    "\n",
    "eval_dict = {}\n",
    "ground_truth = {}\n",
    "\n",
    "for race in val_horse_race_df['race_id'].unique():\n",
    "    race_df = val_horse_race_df[val_horse_race_df['race_id']==race]\n",
    "    n_horse = race_df.shape[0]    \n",
    "    eval_dict[race] = {}\n",
    "    eval_dict[race]['ground_truth'] = race_df['clean_position'].values\n",
    "    eval_dict[race][pred_col] = race_df[pred_col].values\n",
    "\n",
    "\n",
    "eval_result, lgbrank_timeprog_results_df = evaluate_prediction_sets(eval_dict)\n",
    "lgbrank_timeprog_results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce20b707-ec13-402e-ae80-76b3f517b29d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9c6c04-fcc9-4b2f-83b3-574e98fe6d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df5409e-9ffe-4e41-b82f-863807fe7dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50a4cbf0-8af9-43e3-9830-fe63d39eca5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        feature  feature_importance\n",
      "0                clean_win_odds                1241\n",
      "1                 dweight_delta                 875\n",
      "2             awght_dwght_ratio                 810\n",
      "3   clean_declared_horse_weight                 757\n",
      "4                 aweight_delta                 674\n",
      "5             awght_dwght_delta                 653\n",
      "6                       trainer                 540\n",
      "7                        jockey                 521\n",
      "8           clean_actual_weight                 388\n",
      "9                  horse_number                 349\n",
      "10                race_distance                 291\n",
      "11                  jockey_freq                 253\n",
      "12       race_course_track_freq                 226\n",
      "13            race_course_track                 200\n",
      "14                 trainer_freq                 192\n",
      "15              race_class_freq                 164\n",
      "16         track_condition_freq                 108\n",
      "17             race_class_bin_2                  62\n",
      "18                trainer_bin_4                  55\n",
      "19        track_condition_bin_3                  51\n",
      "20             race_class_bin_3                  47\n",
      "21      race_course_track_bin_3                  46\n",
      "22             race_class_bin_1                  46\n",
      "23                trainer_bin_6                  45\n",
      "24      race_course_track_bin_1                  44\n",
      "25                  race_course                  42\n",
      "26                trainer_bin_5                  42\n",
      "27      race_course_track_bin_0                  41\n",
      "28                trainer_bin_3                  40\n",
      "29                 jockey_bin_1                  39\n",
      "30        track_condition_bin_2                  38\n",
      "31                 jockey_bin_4                  37\n",
      "32                   race_class                  37\n",
      "33      race_course_track_bin_2                  37\n",
      "34                 jockey_bin_6                  36\n",
      "35                 jockey_bin_2                  35\n",
      "36                trainer_bin_1                  34\n",
      "37                trainer_bin_2                  33\n",
      "38                trainer_bin_0                  32\n",
      "39                 jockey_bin_5                  32\n",
      "40                 jockey_bin_3                  31\n",
      "41                 jockey_bin_0                  26\n",
      "42        track_condition_bin_1                  17\n",
      "43            race_course_bin_0                  11\n",
      "44             race_class_bin_0                  11\n",
      "45              track_condition                   9\n",
      "46             race_course_freq                   2\n",
      "47        track_condition_bin_0                   0\n"
     ]
    }
   ],
   "source": [
    "reload(project_utils)\n",
    "impt_df = project_utils.lgbm_feature_importance(model_rank)\n",
    "print(impt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68d3f77-3bf8-4b67-9779-55f48c512fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py310] *",
   "language": "python",
   "name": "conda-env-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
